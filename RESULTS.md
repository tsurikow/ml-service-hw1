## Что было сделано

* Проведен анализ данных по двум датасетам с заполнением пропусков и удалением дубликатов
* Выявлены выбросы в тренировочных данных, оставлены как есть
* Столбец **torque** был удален для упрощения модели, в идеале из него следовало бы выделить дополнительные признаки
* Визуализация данных произведена через библиотеки **seaborn** и **matplotlib**
* Сформированы дашборды по обоим датасетам через **[ydata-profiling](https://github.com/ydataai/ydata-profiling)**: [df_train](df_train.html), [df_test](df_test.html)
* Обучены и применены несколько линейных моделей с подбором параметров
* Столбец **name** закодирован с применением `TargetEncoder(categories='auto', target_type='continuous', smooth='auto')`
* Категориальные переменные закодированы с применением `OneHotEncoder(sparse_output=False, drop='first', handle_unknown='ignore')`
* Реализована бизнесовая метрика
* Лучшая модель на тестовой выборке показала метрики:

  ```
  MSE: 77004231939.74
  RMSE: 277496.36
  R^2: 0.87
  Ridge (+name): 0.268 # business metric
  ```

### Наибольший буст в качестве

Наибольший буст в качестве дало кодирование категориальных переменных и кодирование столбца **name** по целевой переменной

## Сервис FastAPI

* В сервисе реализовано два метода POST: **/predict_item** и **/predict_items**
* Первый принимает один экземпляр объекта в виде JSON, а возвращает результат предсказания модели в виде float
* Второй принимает файл .csv с множеством объектов и возвращает исходный файл .csv с дополнительным столбцом с предсказанными значениями целевой переменной
* Данные принимаются в необработанном виде, обработка реализована отдельной функцией **preprocessing** с применением **pandas**. Этапы обработки повторяют то, что было сделано раннее в [AI_HW1_Regression_with_inference_base.ipynb](AI_HW1_Regression_with_inference_base.ipynb)
* Валидация данных реализована с применением **pydantic** и **fastapi**
* Отдельная валидация объектов Item происходит после открытия успешной загрузки и открытия файла .csv: если данные успешно прошли валидацию, то мы получим в ответе заголовок, подтверждающий это; если во время валидации возникли ошибки, то в заголовке ответа будут присутствовать все ValidationError'ы в виде JSON. Такое решение было принято потому, что часть данных из cars_test.csv не проходят валидацию, но успешно обрабатываются на стадии препроцессинга. Но в идеале мы должны были бы выдавать прерывающую ошибку валидации до стадии препроцессинга и предсказания, а не принимать невалидные данные.
* Файлы .csv обрабатываются посредством программной библиотеки **pandas**

## Что можно было сделать, но сделано не было

* Обработать столбец **torque**
* Поэкспериментировать с категориальными переменными, не все из них могут быть полезными
* Обучиться на всей выборке
* Реализовать кастомный transform
* Реализовать полноценный Pipeline
* Предсказывать сразу несколькими моделями

## Аннотация к файлам в репозитории

1. [AI_HW1_Regression_with_inference_base.ipynb](AI_HW1_Regression_with_inference_base.ipynb) – ноутбук с анализом и моделями
2. [cars_test.csv](cars_test.csv) – df_test, который использовался по заданию в ноутбуке
3. [df_train](df_train.html), [df_test](df_test.html) – .html файлы с дашбордами
4. [example.json](example.json), [examples.csv](examples.csv) – примеры запросов, проходящих валидацию
5. [main.py](main.py) – код сервиса FastAPI
6. [models.pkl](models.pkl) – .pickle файл с dump'ами кодировщиков и лучшей модели из ноутбука
7. [output_model.ipynb](output_model.ipynb) – облегченная версия ноутбука (для ускорения запуска и выгрузки файлов для сервиса)
8. [requirements.txt](requirements.txt) – необходимые библиотеки для проекта в PyCharm
9. [result.csv](result.csv) – возвращаемый сервисом .csv файл из исходного [cars_test.csv](cars_test.csv)
